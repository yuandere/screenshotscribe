from enum import Enum
import os

from dotenv import load_dotenv
import google.generativeai as genai
from tqdm import tqdm
from google.generativeai.types import HarmCategory, HarmBlockThreshold

load_dotenv()
genai.configure(api_key=os.environ['GEMINI_API_KEY'])
model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    safety_settings={
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH
    },
    system_instruction="You are an assistant tasked with accurately transcribing text from user-submitted images. Return the text in string format but leave out content clearly irrelevant to the image subject. For example- UI elements, system time in a phone screenshot or an ad near a social media post. If no text is found in the image return '<NO TEXT FOUND>'"
)


class FinishReason(Enum):
    FINISH_REASON_UNSPECIFIED = "Default value. This value is unused."
    STOP = "Natural stop point of the model or provided stop sequence."
    MAX_TOKENS = "The maximum number of tokens as specified in the request was reached."
    SAFETY = "The response candidate content was flagged for safety reasons."
    RECITATION = "The response candidate content was flagged for recitation reasons."
    LANGUAGE = 'The response candidate content was flagged for using an unsupported language.'
    OTHER = "Unknown reason."
    BLOCKLIST = "Token generation stopped because the content contains forbidden terms."
    PROHIBITED_CONTENT = "Token generation stopped for potentially containing prohibited content."
    SPII = "Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII)."
    MALFORMED_FUNCTION_CALL = "The function call generated by the model is invalid."


def map_finish_reason(value):
    if value == 0:
        return FinishReason.FINISH_REASON_UNSPECIFIED
    elif value == 1:
        return FinishReason.STOP
    elif value == 2:
        return FinishReason.MAX_TOKENS
    elif value == 3:
        return FinishReason.SAFETY
    elif value == 4:
        return FinishReason.RECITATION
    elif value == 5:
        return FinishReason.LANGUAGE
    elif value == 6:
        return FinishReason.OTHER
    elif value == 7:
        return FinishReason.BLOCKLIST
    elif value == 8:
        return FinishReason.PROHIBITED_CONTENT
    elif value == 9:
        return FinishReason.SPII
    elif value == 10:
        return FinishReason.MALFORMED_FUNCTION_CALL
    else:
        return "Unknown"


def handle_finish_reason(api_response):
    candidates = api_response.candidates

    if candidates:
        candidate = candidates[0]
        # Gemini API returns an integer instead of an enum value
        finish_reason_enum = candidate.finish_reason

        # finish reason 1 is good; API responded with no issues
        if finish_reason_enum == 1:
            return 1
        else:
            # use mapping function to get the enum name
            finish_reason_str = map_finish_reason(finish_reason_enum)

            message = f"Error: Gemini API returned {
                finish_reason_str} https://ai.google.dev/api/generate-content#FinishReason"
    else:
        message = "Error: No candidates returned."

    return message


def prompt_API(image_path):
    filename = os.path.basename(image_path)
    date_created = os.path.getctime(image_path)

    myfile = genai.upload_file(image_path)
    response = model.generate_content(myfile)

    finish_reason = handle_finish_reason(response)
    if finish_reason == 1:
        text = response.text.strip()
    else:
        text = finish_reason

    return {
        "filename": filename,
        "date_created": date_created,
        "text": text,
        "success": True if finish_reason == 1 else False
    }


def generate_text_gemini(image_paths):
    data = []
    for image_path in tqdm(image_paths):
        image_data = prompt_API(image_path)
        data.append(image_data)

    return data
